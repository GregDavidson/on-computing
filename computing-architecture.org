* What Computers Are: Architecture

Part of the [[https://github.com/GregDavidson/computing-magic#readme][Computing Magic]] Curriculum.

** Read This First!

This is an [[https://orgmode.org][OrgMode]] Document. Although OrgMode documents are just text, this
particular document makes extensive use of OrgMode support for Folding and
Unfolding sections. Unfortunately, GitHub does not support this. We suggest that
you copy this file (or even clone the whole repository) and then read this
document with Emacs Org Mode. A path to learning Emacs and Orgmode is in our
[[https://github.com/GregDavidson/computing-magic/blob/main/Software-Tools/Emacs/emacs-readme.org][Emacs Readme]].

** Introduction

People who simply use applications running on computers don't need to
know much about
- How the applications work
- How the operating system supporting the applications work
- How the computer's hardware works
- And the architecture which fits those things (and more) together.

Who needs to understand Computer Architecture?
- Programmers :: some parts!
- System Administrators :: some other parts!
- Serious Learners :: Computers are an important part of our world!

The Architecture of most modern computers is similar in general with large
amounts of differences in detail. It consists of a number of layers which
communicate only to adjacent layers.

The next part of this document is structured using nested sections imitating the
architecture of a typical modern Computer System which includes Unix and the
Unix-imitating Gnu/Linux and MacOS and even the but deviant (but significantly
Unix-culture-influenced) Microsoft Windows.

Many of the terms in this document are defined in our [[file:computing-glossary.org][Computing Glossary]].

** A Modern Computer System
*** User Space

/User Space/ is the "space" (in the sense of an arena or environment) provided
by an /Operating System/ providing resources needed to run /Computer Programs/
reliably.

/Programs/ running in /User Space/ are contained within /Tasks/, usually called
/Processes/. /Processes/ are associated with specific /User Accounts/ and
/Groups/ which have associated /Permissions/ which limit what those /Processes/
are allowed to do.

The Kernel and the Hardware protects /User Space/ /Processes/ from the System
from accidentally or intentionally interfering with each other or with Operating
System components.

The Operating System also provides /User Space/ /Processes/ with many convenient
services. The bottom line is that it is much, much easier to write /User Space/
/Programs/ than the alternative of adding code to the /Kernel/ which runs in
/Kernel Space/.

Details of /User Space/ Services, the /Kernel/ and /Kernel Space
are provided in sections below.

Programs running in /User Space/ include

**** Interactive Applications, aka Apps

Interactive Application Programs (apps) are programs intended to interact with
users through some kind of /User Interface/ such as a
- Console User Interface :: Uses a /Text Console/ or /Terminal App/
- /Graphical User Interface/ :: Uses a /Graphical Display/
- /Web Interface/ :: Uses a /Web Browser/

**** Non-Interactive Commands

/Power Users/ who understand /Command Shells/ can start simple or complex
Commands to perform desired tasks without further interaction.

/Power Users/ can also direct non-interactive commands to run automatically when
appropriate situations arise.

A mini-curriculum for learning this style of computing is [[https://github.com/GregDavidson/computing-magic/blob/main/Scripting/README.org][HERE]]!

**** System Services, aka Daemons

/System Services/ can either be provided by code in the /Kernel/ or they can run
as programs in /User Space/. Unless a system service requires some special
access to hardware which is only available in /Kernel Space/, it is generally
better for it to run as a program in /User Space/.

Example System Services
- init or /SystemD/ :: starts and controls the other system services
- login daemons :: start a user's session when they log in
- logging daemons :: log status and error messages for diagnostics
- thermald :: adjust CPU frequency to prevent overheating
- sshd :: provides secure connections to accounts on other computers
- httpd :: provides access to locally stored or generated web pages
- and many more!

***** Show Me!

This one-line script will list the daemons running on your system
#+begin_src sh
  ps aux | awk 'NR==1||($1=="root" && $7=="?" && $11 !~ /\[/){print $2, $11}'
#+end_src

#+RESULTS:
|    PID | COMMAND                                  |
|      1 | /sbin/init                               |
|    385 | /lib/systemd/systemd-journald            |
|    419 | /lib/systemd/systemd-udevd               |
|    764 | /usr/lib/accountsservice/accounts-daemon |
|    766 | /usr/sbin/acpid                          |
|    772 | /usr/lib/bluetooth/bluetoothd            |
|    774 | /usr/sbin/cron                           |
|    778 | /usr/sbin/NetworkManager                 |
|    783 | guix-daemon                              |
|    786 | /usr/sbin/irqbalance                     |
|    796 | /usr/bin/python3                         |
|    803 | /usr/lib/policykit-1/polkitd             |
|    813 | /lib/systemd/systemd-logind              |
|    815 | /usr/sbin/thermald                       |
|    820 | /usr/lib/udisks2/udisksd                 |
|    821 | /sbin/wpa_supplicant                     |
|    887 | /usr/sbin/ModemManager                   |
|    974 | sshd:                                    |
|   1110 | /usr/sbin/lightdm                        |
|   1188 | /usr/lib/upower/upowerd                  |
|   1224 | lightdm                                  |
|   1264 | /lib/systemd/systemd                     |
|   1265 | (sd-pam)                                 |
|   1755 | fusermount                               |
|  66169 | sshd:                                    |
| 236151 | /usr/sbin/cupsd                          |
| 236152 | /usr/sbin/cups-browsed                   |

***** How can I learn more?

You can use the =whatis= command to get a 1-line description of most things
#+begin_src sh :results list drawer
  whatis cron
  whatis sshd
  whatis chmod
  whatis whatis
  whatis man
#+end_src

#+RESULTS:
:results:
- cron (8)             - daemon to execute scheduled commands (Vixie Cron)
- sshd (8)             - OpenSSH daemon
- chmod (1)            - change file mode bits
- chmod (2)            - change permissions of a file
- whatis (1)           - display one-line manual page descriptions
- man (7)              - macros to format man pages
- man (1)              - an interface to the system reference manuals
:end:

The online reference manual is divided into 8 sections
#+begin_src sh :results list drawer
  whatis intro | sort
#+end_src

#+RESULTS:
:results:
- intro (1)            - introduction to user commands
- intro (2)            - introduction to system calls
- intro (3)            - introduction to library functions
- intro (4)            - introduction to special files
- intro (5)            - introduction to file formats and filesystems
- intro (6)            - introduction to games
- intro (7)            - introduction to overview and miscellany section
- intro (8)            - introduction to administration and privileged commands
:end:

You can then use the =man= command (with optional -s SECTION-NUMBER) in a
terminal to get to see the reference manual entry on that command:
- =man man= # how to use the =man= command
- =man ssh= # how to use the =ssh= client for the =sshd= server
- =man -s 1= chmod # how to use the =chmod= command
- =man -s 2= chmod # how to use the =chmod= system call

Same commands in Emacs:
- M-x man <ENTER> man <ENTER>
- M-x man <ENTER> ssh <ENTER>
- M-x man <ENTER> ssh(1) <ENTER>
- M-x man <ENTER> ssh(2) <ENTER>

Please note that the /Reference Manual/, which should be available on every
/Posix/ system, is a Reference, /not/ a Tutorial. For Tutorials try searching
the Web.

**** Compiled Programs are Translated In Advance

The /Source Code/ is written in a /High-Level Programming Language/.
- Ideally in terms of /High-Level Abstractions/
- Available on any modern /Operating System/
- Such a program is therefore /Portable/
      - It should run the same on any modern computer

Machines can't execute /High-Level Languages/ directly
- The /Source Code/ is translated (compiled) to Machine Language
- The translated code is stored in an /object code/ file
      - Either an executable program file
            - Microsoft uses the extension =.exe= for such files
            - Posix uses /no/ extension for such files
      - or a library file
            - Microsoft uses the extension =.dll=
            - Posix uses =.a= for archive libraries, =.so= for /Shared Object/ Files
- Translation is done /in advance/, before the program is run
- /The object code file is not portable!/
      - It will only run on one kind of computer system

Few programmers understand machine language, or need to
- Different kinds of computers have different machine languages
- None of them are designed to be easily understood by humans

Users might have only the machine language, e.g. a =.exe= file.
- They can only run a =.exe= /as is/
- /Open Source Free Software Licenses/ require distributors to provide Source
  Code to Users

Having the Source Code makes it possible to
- Check the program for security weaknesses or backdoors
- Rebuild the program for another kind of computer
- Study how the code works
- Fix a bug
- Improve the program for one's own needs
- Hire someone else to do such things for you!
- Or benefit from community creativity
      - Many programmers continuously improve interesting software
      - Most of the internet infrastructure is Open Source Free Software!

**** Interpreted Programs are Translated As The Application Runs

- The application file is /Source Code/ in that language
- There must be an /Interpreter Program/ which understands that language
- The /Interpreter Program/ is a /Compiled Program/
- When you run your application
      - The Interpreter for that language is started instead
      - The Interpreter performs (interprets) the program
            - like an actor performing a scripted role
            - hence these programs are often called /Scripts/
      - /Interpreted Code/ usually runs /much slower/ than /Compiled Code/
            - E.g. Interpreted Python is around 50 times slower than
              compiled C or Rust
      - A few Interpreted languages have partially overcome this
            - E.g. Java is often 1/3 as fast as C or better
                  - though often using 3 times as much memory
            - E.g. JavaScript is often 1/5 as fast as C or better
                  - though often using 5 times as much memory
      - The techniques to achieve this are quite challenging!
            - E.g. [[https://en.wikipedia.org/wiki/Just-in-time_compilation][Just-in-time compilation]]
      - Interpreted Programs often leverage fast libraries written in Compiled Languages
            - Programmers wind up limited to what available libraries can do
            - Or they have to learn to write such libraries themselves

Sometimes interpreted programs are /obfuscated/ before being distributed
- translated into a program incomprehensible to humans
- to prevent empowering users with access to proper source code

***** Leveraging a variety of Libraries and Services

These may be provided any or all of
- Language-specific support or extension features
- Third-Party extensions
- /Operating System/ core or added features

These constitute /dependencies/ which are required to be present on your system
in order for your application to run.

There are a variety of tools and techniques designed to be sure that all
applications are supplied with the right version of the needed dependencies when
the application is installed or updated.

**** Libraries

Libraries consist of parts of programs, most often procedures or classes which
provide functionality often needed by programs.

Providing such functionality in the form of a library saves programmers the
effort of implementing that common functionality in their programs.

Any libraries needed by a program have to be /linked/ with the program in order
for that program to function. This can either be done in advance, which is
called /static linking/ or at the time the program is run (or even later when
the program needs that functionality) which is called /dynamic linking/.

/Static linking/ has the advantage that the program file is complete and will
run even if a library it uses is not available on the system where the
application is installed. /Static linking/ has the disadvantage that the program
file is larger.

/Dynamic linking/ not only saves space when a library is used by many installed
programs, but it can also make it easier to provide updates, e.g. fixing
security flaws, by simply updating the libraries. Making sure that appropriate
versions of all the libraries needed by all of the installed programs used to be
a tedious administrative task. Nowadays that task is largely or completely
automated by automated /package managers/.

/Novice Programmers/ often imagine that code in libraries is free of bugs or
security or reliability issues. Alas this is not the case! Libraries need to be
audited for quality and should ideally be /Open Source Free Software/!

**** Processes and Programs

***** /User Space/ consists of /Tasks/ running /Programs/.

/Tasks/ are also called /Processes/ although there is another kind of process
called /Threads/, covered below, which are different!

The /Kernel/ creates /Tasks/
- in response to /System Calls/
- issued by /Programs/
- running inside existing /Tasks/
Wait, that's circular!  How does it get started?

After the bootstrapping system loads and starts the Kernel
- The Kernel builds the first task
      - Traditionally called /init/
      - /Init/ has Process ID 1
- All other Tasks are created by requests from existing Tasks.

We'll describe the original /Unix Model/ which is supported by Linux, BSD and
other Unix-like or /Posix/ Operating Systems. Later /Posix/ systems often
provide additional ways of doing things and Microsoft Windows has always been a
bit different.

The original System Calls include
- =fork= :: creates a /Process/
- =exit= :: terminates the /Process/ calling it
- =wait= :: suspends processing until a /Child Process/ calls =exit=
- =exec= :: runs a new /Program/ in an existing /Process/

***** The Life Cycle of a Process (Task)

- An existing Process calls =fork=
- The Existing Process is called the /Parent Process/
- The Kernel responds by
      - Creating a /Child Process/ with a new Process ID aka PID
      - which is otherwise /identical to the Parent!/
The two identical processes execute in parallel
    - Both find themselves returning from =fork=
          - The Parent receives the Child's PID
          - The Child receives 0
    - Both processes examine that return value
          - They discover whether they're the Parent or the Child
          - They then set about their proper task
          - As written in the program they're both executing!
    - A process calls =exit= when it is done with its work
          - The kernel terminates the process calling =exit=
          - And notifies the /Parent Process/ that a child has exited

***** Why Create Multiple Processes?

Imagine you want to go to the beach and enjoy yourself
- but you have chores you need to do
If life worked like /Unix/
- You could /Fork A Child/ to run your chores for you
- It knows just what to do, because it's an exact copy of you!
- While the Child is doing the chores
- The Parent is having a good time at the beach!

In general, you want to create Multiple Processes
- When there are multiple things that need to be done
- And you don't want to do just one at a time
- You don't want them to wait for one another

***** So How Do You Do It?

In the usual situation
- a /Parent/ creates a separate /Child/ for each responsibility
- each child starts its task as soon as it returns from =fork=
- after all children are created, the /Parent/ repeatedly calls =wait=
      - each call to =wait= suspends the /Parent/ until a /Child/ exits.
      - when a /Parent/ returns from =wait= it receives
            - the PID of the child which has exited
            - the /exit status/ provided by that child

When a process calls =exit=
- It supplies an /exit status/ argument
- By convention:
      - /exit status/ =0= means /success/ or /true/
      - a non-zero /exit status/ means /failure/ or /false/
      - but you can use exit statuses to mean what you like
            - they just have to be an integer in the range =0= to =127=

The Parent is responsible for coordinating the Children
- If a Child fails its task, the Parent can, e.g.
      - =fork= a new Child to try again
      - Using the same or a different strategy
      - Or just report the failure appropriately

****** Show Me Some Code!

***** How do you Run a New Program?

When a program calls =exec=
- it's asking the Kernel to replace it with a new program
- running in the same process
- the old program and its memory space will be discarded
- the new program gets a new memory space
- the new program starts execution at the beginning
      - typically with a call to a procedure called =main=

The Kernel automatically creates a new /Virtual Memory Space/ big enough for the
new program to start. Most programs don't need more, but if they do, there are
System Calls to request more.

****** Show Me Some Code!

**** Tasks are Heavyweight Processes

Tasks
- encapsulates several expensive system resources
- are therefore fairly expensive to create and to maintain
Tasks are also called /Heavyweight Processes/
- or just /Processes/ for short
- /(there's another kind of Process called a Thread which we'll explain later)

Heavyweight Processes Contain

**** Containing a Program in an Image

Programs are stored as files outside of system memory.

When you "run" a program with =exec=, the Kernel
- Creates a Virtual Memory Space
- Maps the program's file into that virtual memory space
- Includes any Options and Arguments passed to =exec=
      - Traditionally from command used to run the program
- All of this is called an /Image/.

**** Virtual Memory

- Each /Task/ appears to have a separate /Memory Space/
      - With addresses from =0= to some large number
- =exec= makes sure there's enough memory for the new program to start
      - The program can request more as needed
- Memory cannot be accidentally shared across /Tasks/
      - A numerical addresses in one Image has nothing to do with the
        same numerical address in another Image
- /Physical Memory/ is mapped as needed or requested into /Virtual Memory/
      - Memory is allocated in chunks called /Pages/
      - Each /Page/ in /Physical Memory/ has a /Physical Memory Address/
      - From =0= to however much /Physical Memory/ your machine actually has
      - Any /Page/ in /Physical Memory/ can be assigned an address in some one Process's Virtual Memory
      - Processes can't see the /Physical Memory Addresses/
      - Processes can't see any memory belonging to another Process

***** Special Virtual Memory Features

There are some special features with Virtual memory. Some of them can allow
Processes to share parts of their Virtual Memory with other Processes.

****** Memory Mapped Files

You can map an area of physical memory to a file in a file system
- Or anything which can act like a file (more on that later)

When a program tries to access such a region of its memory
- The Kernel pauses the process
- The Kernel allocates enough real memory to hold the page(s) being accessed
- The Kernel reads that data from the "file" into the allocated memory
- The Kernel resumes the program

- It's also possible to arrange for modifications in such a mapped area of
  memory to propagate out to the "file".
- /This can allow processes to Communicate as with Shared Memory (see below)!/

This may seem like it has more overhead than the usual file Input/Output
mechanisms, but it is in fact 2-3 times faster! Many high-performance programs
map their files rather than reading or writing them in the usual way.

******* Programs and Dynamic Libraries are Mapped!

Remember that /Programs/ and Dynamic Libraries live in Files.

When you "run" a /Program/
- the program's File is /Memory Mapped/ into the Image memory of the Task
- The code of any Dynamic Libraries is also Memory Mapped into the Image memory
- Only the Pages of the Program and/or Library Code which are actually accessed
  during the run of a program will actually wind up being /Paged In/.
- Thus large programs with lots rarely used features don't necessarily require
  so much memory to run!

****** Shared Memory Segments

Processes can ask the Kernel to create /Shared Memory Segments/.

A Shared Memory Segment is
- a collection of contiguous pages of Virtual Memory
- with ownership and read/write permissions
- similar to a Files in a Filessytem

So it's not a file
- but it a lot like a file
- so it's a kind of "file"!

One or more processing running on the same computer system
- which might be a cluster or distributed computer
- with many CPUs and Memory banks
- communicating over high-speed buses
can map the same Shared Memory Segment into their Virtual Memory Spaces
- if the Shared Memory Segment's "file" permissions allow it

Each process mapping a particular Shared Memory Segment
- into their normally "Private" Virtual Memory
- can map it at an address of their choosing in their Memory Space

Yes, that means that any data in such a Shared Memory Segment may
appear to be at different addresses within different Processes!

Programmers Beware:
- Do not store Pointers (memory addresses treated as data) in such Shared Memory
  Spaces!
- Such Pointers will reference a different memory area from the viewpoint of
  other Processes
- And High-Level Languages use Pointers to reference just about everything!

Modifying data in Shared Memory Segments mapped into multiple Proccesses on the
same Computer allows for a very fast form of Input/Output.

An example is in the architecture of the PostgreSQL advanced Object-Relational
Database System. A PostgreSQL Parent Process creates a Child Process to serve
each database client. Database clients communicate with their PostgreSQL service
process using regular I/O, usually TCP/IP Sockets. The PostgreSQL Child
Processes communicate with their Parent (which coordinates access to the
database) via Shared Memory Segments.

****** Paging and Swapping

Modern Computers are very fast:  In a single second
- They can do billions of operations with main memory
- They can move many millions of bytes in or out of memory

When physical memory is running low, the Kernel can
- Determine what Pages of Memory haven't been used in a long time
      - i.e. in the last tenth of a second or so!
- /Page Out/ pages of memory or /Swap Out/ whole Images of Tasks
      - Moving any modified Pages to a /Disk Volume/ called the /Swap Space/
      - Memory mapped to come right back in if and when needed

When there's not enough /Swap Space/ and memory gets really low
- The kernel will select and kill Processes as necessary
- So that the system continues to be as usable as possible
- This sometimes happens, e.g. to browsers with hundreds of tabs!

Programmers Beware: This possible occurrance is just one of the things which can
cause a Process to be terminated unexpectedly. You must design your program so
that if it crashes (terminates unexpectedly at any time) you won't corrupt any
important data you might have been in the middle of updating! Ensuring this can
be challenging!

**** Threads are Lightweight Processes

A thread represents an execution sequence within a program, tracking the next
instruction to execute within the program. This is a virtualization of the
traditional hardware /Program Counter/.

On some systems a Thread may also include one or more pages of Thread Specific
Memory within that Image which other Threads are /not supposed to access/. But
there's no actual mechanism to prevent them from accessing another thread's
Thread Specific Memory. And accidentally doing so can cause program errors which
are very difficult to debug!

That's all that comprises a Thread, so Threads are very lightweight when
compared with /Tasks/. For this reason Threads are also called /Lightweight
Processes/.

When =exec= causes the Kernel to "run" a new Program within a task, the Kernel
creates a /Main Thread/ which calls that Program's starting point (in many
languages, a procedure called =main=) and the program is off and running!

A program can request the Kernel to create additional Threads as desired.

Modern computers increasingly have multiple CPUs and GPUs aka Hardware
Processors. If a Task has N Threads and the machine has M processors and if N
> M then it won't be possible for all of the threads to be running at once. In
practice, all of the Threads of all of the Tasks in /User Space/ are competing
for access to the system's Processors (CPUs and also sometimes GPUs).

The solution to this delemma is Time Slicing. Because Processors are so very
fast, it's possible for each one to spend a few milliseconds doing work for one
thread, then the next few milliseconds doing work for another thread, and so on.
One Processor can handle the needs of any number of Threads if necessary. This
is especially true since it's common for Threads to spend much of their time
waiting for events or data and therefore not ready to run.

Operating Systems have sophisticated ways of prioritizing the access of Threads
to Processors so that important processing activities can advance as fast as
possible at the expense of activities which can afford to wait a bit.

****** Show Me Some Code!

**** Virtual I/O

***** - Tasks do I/O through /File Descriptors/

/File Descriptors/ live in /Kernel Space/
- The /Kernel/ keeps a table of their /File Descriptors/ for each /Task/
- The /Program/ uses /Index Numbers/ to specify which /File Descriptor/ to use
- We'll use *FD* to refer to those /Index Numbers/, not to actual File Descriptors
- There's a way to /Redirect/ Inputs and Outputs to new Sources or Sinks
      - See /Redirection/ below!

I/O is normally done with Bytes using Sources or Sinks
- A Source is an Input Stream which is a provide of Bytes
- A Sink is an Output Stream which can receive Bytes

- A /File/ is a Source when you read Bytes from it
- A /File/ is a Sink when you
      - append Bytes to it -- existing contents remain
      - overwrite it -- new Bytes replacing some existing Bytes
      - rewrite it -- all old bytes discarded, new Bytes replace them

/File Descriptors/ are not necessarily associated with /Files/!
- A /Pipe/ connects an Output Descriptor of one Task with an Input Descriptor of another Task
- A /Network Stream/ connects
      - a /File Descriptor/ of some Task T1 on some Computer C1
      - with another /File Descriptor/ of some Task T2 on some Computer C2
      - C1 and C2 could be anywhere on any computer network, e.g. the Internet

- Three FDs should always exist
      - =0= :: /Standard Input/ traditionally connected to a user's keyboard
            - Can be connected to any /Input Stream/ which produces /Bytes/
                  - including a /File/ /Open/ for /Reading/
                  - or a /Pipe/ /Output/ or a /Readable/ /TCP Network Stream/, etc.
      - =1= :: /Standard Output/ traditionally connected to a user's Terminal Display
            - Can be connected to any /Output Stream/ which can consume /Bytes/
                  - including a /File/ /Open/ for /Writing/ or /Appending To/
                  - or a /Pipe/ /Input/ or a /Writeable/ /TCP Network Stream/, etc.
      - =1= :: /Standard Output/ traditionally connected to a user's Terminal Display
            - If a program has one main output stream, this will be it
            - FD =1= is often /Redirected/
      - =2= :: /Standard Error/ traditionally also connected to a user's Terminal Display
            - If a program needs to report an error, this is the traditional FD for it
            - /Standard Error/ is especially useful when FD =1= has been /Redirected/

***** - System Calls for Regular I/O

Remember that most Application Programs use more convenient High-Level
Libraries. But those Libraries are ultimately using these System Calls.

Since File Descriptors live in /Kernel Space/
- The /Kernel/ must perform all I/O for all /Tasks/
- This includes both Local I/O and Network I/O

Traditional Fundamental I/O System Calls include
- =open(PATH, FLAGS)= :: Open a File at PATH, Creating a File Descriptor
      - Returns a FD Index or -1 if an error
      - the FLAGS specify how you want to use the file, e.g. to read it, rewrite it or append to it.
- =close(FD Index)= :: Close the corresponding /File Descriptor/, no more operations will be accepted
- =read(FD Index, POINTER, NUM_BYTES)= :: Read up to NUM_BYTES into memory at POINTER
      - May read fewer than NUM_Bytes
            - if at end of a file
            - if pipe or network channel has no more bytes
      - Returns the actual number of bytes read, or -1 on error
- =write(FD Index, POINTER, NUM_BYTES)= :: Write up to NUM_BYTES from memory at POINTER to the FD
      - May write fewer than NUM_Bytes
      - Returns the actual number of bytes read, or -1 on error
- =ioctl(FD Index, REQUEST, ...)=  :: Do something else with a File Descriptor
      - =ioctl= is for miscellaneous operations, each specified by an Integer REQUEST number
      - Different kinds of files and devices provide different possible REQUESTs
      - The other arguments are specific to the REQUEST number and device

****** Show Me Some Code!

Link to
- an example of C Code directly using the System Calls
- an example of Racket Code using a High-Level Library facility

***** - Redirection Is A Nice Feature!

In the Unix model, new FDs are always the smallest index number possible.
- If all FDs up to a certain number are all in use
- And then you close one of them, say FD #X
- And then you ask for a new File Descriptor
- You're guaranteed that the new FD is FD #X
- This peculiar property allows us to /redirect/ descriptors!

- dup, dup2, dup3 :: Duplicate an existing File Descriptor
      - With the original =dup=, the new FD was always the smallest
      - =dup2= let's you specify which descriptor to replace with the duplicate
      - =dup3= is like =dup2= except the new descriptor will automatically close
        the next time the /Program/ calls =exec=.

Suppose
- A Program is doing I/O on FD #Old
- all descriptors below #N are in use.
Given another (possibly new) /File Descriptor/ with FD #New
- After =close(Old), dup(New)=
- Further I/O with FD #Old is now using File Descriptor #New!
- You can now =close(New)= if you've no further use for it

This dance is now obsolete, the new dance is
- A Program is doing I/O on FD #Old
- There's another /File Descriptor/ with FD #New
- After =dup2(Old, New)=
- Further I/O with FD #Old is now using File Descriptor #New!

****** Show Me Some Code!

Link to
- an example of C Code directly using the System Calls
- an example of Racket Code using a High-Level Library facility

 You can now =close(New)= if you've no further use for it

***** Network I/O

Remember that most Application Programs use more convenient High-Level
Libraries. But those Libraries are ultimately using these System Calls.

A key problem with network I/O is how to Rendezvous (find one another)
- Local I/O traditionally uses Filesystem Paths to rendezvous
      - Local Network I/O can also use such!
- General network I/O uses Sockets to Rendezvous and to Communicate
      - On /Posix/ Systems, Sockets are just a kind of /File Descriptor/
- Sockets belong to a particular Network Family, e.g. Unix (Local) or Internet
- Internet Sockets are labeled with three properties
      - Protocol: Either Stream or Datagram
      - Port: A 16-bit number identifying a FD of a local Task
      - IP Address: A number identifying a particular computer
            - IP Addresses identify to things:
                  - what network the computer is on
                  - the specific computer on that network
            - IPv4 addresses are 32-bit numbers
            - IPv6 addresses are 128-bit numbers
      - The Domain Name System tranlates the Domain part of a URL into an IP Address
            - So you can change the IP Address of a computer and still be found!

Networking has a fundamental asymmetry
- A Network Server is a Task providing a Service via a Socket
      - The Network Server needs to be findable by Clients
- A Network Client is a Task which wants access to a Service
      - The Network Client needs to initiate any connection
      - As it's identity is not generally known to the Server

Let's assume we want to create a reliable Byte-Stream connection, e.g. TCP
between a Client and a Server. (The alternative would be to use an unreliable
Datagram service, e.g. UDP which would require us to deal with sending and
verifying the transmission of individual packets.)

The Server Dance, /system calls/ indicated =like this=
- Create a =socket= with the desired Family and Protocol
- =bind= a well-known (advertised) Port Number to the Socket
- This is a /Rendezvous Socket/ which will /not be used for communication!/
- =listen= creates a Kernel queue for arriving Client File Descriptors
- =accept= suspends the /Server Task/ until a Client connects
      - returns /a new socket/ to use in communicating with this Client
      - a Server can have connections to more than one client at a time
- The /Server/ now communicates with the /Client/
      - Possibly with a /New Thread/ so it can =accept= more clients!

The Client Dance
- Create a =socket= with the desired Family and Protocol
- It will be assigned some random unused Port Number
- Use =connect= to attempt to connect to a given Service
      - specifying the IP address of the Server's Computer
      - and the Port Number of the Server's Socket

For Posix Operating Systems, once two Sockets are Connected with a Stream
Protocol, they're just File Descriptors. You can communicate using =read= and
=write= as well as redirect them with =dup=, =dup2= or =dup3= and =close= them
with done.

Microsoft Windows does not consider /Sockets/ to be a kind of /File Descriptor/
so you have to use a different set of /System Calls/ for working with /Sockets/
and simple redirection is not possible.

****** Show Me Some Code!

*** Kernel Space
**** The Kernel

The job of the kernel is to
- Create /User Space/
- Replace idiosyncratic and insecure hardware features with
      - Portable, high-level services
- Prevent Programs running in /User Space/ against
      - Interfering with one another
      - Doing anything disallowed by /Permissions/

Code running in /Kernel Space/ has no such protections.
- All resources of all running programs are accessible
- The computer's hardware is directly accessible
- There are no permissions to worry about
      - Which should make you worry!

Once a computer has finished /Bootstrapping/ the /Kernel/ should be the only
code running in /Kernel Space/!

**** Kernel Services and Examples

The Kernel provides nice high-level abstractions as services to /User Space/ /Tasks/.

***** Processes and Programs

Details are in the last section under /User Space/.

The Kernel is responsible for
- Processes: both Tasks and Threads
- Memory Spaces and Segments
- I/O Connections
- Loading Programs and Libraries

***** File Systems

The /Kernel/ creates the abstractions of /Files/, /Directories/ (Folders) and
/Filesystem Volumes/.

Storage on persistent hardware appears to be in the form of files
- Byte sequences without any apparent physical divisions

Directories (Folders) are /Files/ containing /Links/ to other /Files/
- A /Link/ contains a filename + an /Index Number/
- /Index Numbers/ are unique within /Filesystem Volumes/
- So /Files/ get their names from a /Directory File/
      - Regular Files can have multiple names from multiple /Directory Files/!
- /Directory Files/ get their name from /Parent Directory Files/!
      - /Directory  Files/ are prohibited by policy from having multiple names

Filesystem Volumes abstract physical devices to transparently
- can share physical devices for convenience
- can span multiple physical devices for greater capacity
- can use redundancy to increase reliability and speed (RAID)
- can use encryption for security
- given an /Index Number/ can return
      - The File's /Data/ and /Metadata/
      - A File's Metadata includes /Ownership/ and /Permission/ data

**** The Top Part of the Kernel
The Top Level of the Kernel
- Responds to requests (System Calls) from programs
- Performs the requested action on behalf of the program
      - May or may not suspend the program while doing so
- Places any results into an area of that program's private memory

***** System Calls

From the viewpoint of a programmer, a System Call appears to be a call to a
library Procedure (aka Function). In actuality, a System Call is implemented by
a special piece of machine language code which switches the hardware execution
context from the permissions of /User Space/ to the wide-open permissions of
/Kernel Space/ and calls a procedure within the Kernel.

The thread executing code within the program is suspended while a replacement
thread executing code within the kernel runs code carrying out the action in
Kernel Space. This is invisible to the program, but it is much more expensive
than a regular library procedure. if the program has permission to do the
requested action, the Kernel performs the service for the program.

Programs almost always make System Calls indirectly via higher-level library
procedures which interface better with a particular programming language's
syntax and semantics. It's also common for higher-level library procedures to
use techniques such as buffering to reduce the overhead of System Calls.

**** The Bottom Part of the Kernel

The purpose of the bottom part of the kernel is to interface with physical
devices in order to actually perform such actions and Input/Output, Memory
Mapping, Processor Mapping, etc.

It consists of chunks of code called /Device Drivers/.

A System Call in the Top Part
- creates a Kernel Thread
- which might call a /Device Driver/ procedure to, e.g.
      - load some bytes to be transmitted somewhere
      - initiate the transfer
- and that thread might then suspend itself

The device will inform the device driver when it completes the action
- this is done through a /hardware interrupt/
- which the Kernel translates to
      - the appropriate procedure of the appropriate device driver
- which then might resumes the kernel thread

One of the amazing things about all of this is that
- I/O actions happen at less than a millionth the speed of a CPU
- The kernel needs to manage vast numbers of such operations "at once"
- The devices are often being shared by multiple programs
- Without any interference or even awareness of those programs

Further complicating all of this is that
- Most hardware devices are flakey -- full of dangerous bugs!
- Which are carefully worked around by the corresponding device drivers!

Kernel Programming is not for Wizards, it's for Gurus!

*** Physical Hardware

Physical Hardware consists of a vast number of devices
- There are several kinds of devices
- With numerous variations on each kind of device
- There are usually [[https://xkcd.com/927/][many competing standards]]
      - Real devices imperfectly follow the applicable standards!

**** Mother Boards

A modern computer, including the computers embedded in cellphones and other
consumer or utility devices generally consist of many separate electronic
devices. These are generally assembled on [[https://en.wikipedia.org/wiki/Motherboard][a motherboard]] for physical support and
interconnection.

**** Processors
***** CPUs: Central (General-Purpose) Processing Units
One or more [[https://en.wikipedia.org/wiki/Central_processing_unit][CPU Chip(s)]] provide the execution of the machine code of binary
programs. Modern CPU Chips often incorporate multiple processors along with a
limited amount of memory (called cache) fast enough to keep up with the high
speed of the CPU processors. Modern CPUs may provide other services as well,
e.g. services related to secondary memory and I/O.

***** GPUs: Graphics Processing Units
[[https://en.wikipedia.org/wiki/Graphics_processing_unit][GPUs]] were originally simplified CPUs intended to execute simple repetitive
graphics operations in parallel. As GPUs have evolved they have become able to
take on more and more repetitive tasks in modern computing, e.g. machine
learning and cryptographic processing. Modern GPUs can be programmed with high
level languages. Some programming environments now support compiling parts of
the high-level language code to the CPUs and part for the GPUs to increase
overall throughput.

CPUs and GPUs are often integrated into multi-chip modules which connect to a
motherboard as if they were a single device.

**** Physical Volatile Memory
The main memory of a modern computer consists of DRAM.

DRAM is volatile, it's contents will be lost
- every few milliseconds
      - unless it is refreshed (rewritten)
- or if power is lost

Circuits are provided to refresh DRAM automatically.

DRAM is the main working memory of computers because
- It only costs a few dollars per gigabyte
- It only takes a few nanoseconds to access it

DRAM is too slow to keep up with modern CPUs
- So CPUs use smaller amounts of [[https://en.wikipedia.org/wiki/SRAM][SRAM]] as cache
- 10 times faster, but more expensive!

SRAM and DRAM are both volatile
- So computers use slower non-volatile memory for long-term storage

**** Physical Non-Volatile Memory

There are three popular kinds of non-volatile memory
- Flash -- Used in thumbdrives and "Solid State Drives"
      - 1000 times the latency of DRAM
- Rotating Magnetic Hard Disk Drives -- slower but higher capacity
      - 1000 times the latency of Flash
- Magnetic Tape -- highest capacity, ideal for backups
      - a person or machine has find and mount the right tape!

Increased latency makes these forms of storage look slow.  If the super-fast
processors of the computer have to wait millions of cycles for the data they
need, the system will appear to be very, very slow!

However, if you want a large "chunk" of information and it is stored so that it
can be delivered with a single request, the device can deliver the whole "chunk"
very fast. This is "throughput" as opposed to "latency".

Well written high-performance programs make sure that the data they need to
process is organized and staged so that you can keep the processors busy.

**** Networking

Modern networking breaks up all communication into packets.
- Each packet has a a destination address
- Large chunks of data are can be broken up into multiple packets
      - They'll be reassembled on delivery
- Any number of packets can fail to make it to the destination!
      - Packets are retained at the source until delivery is acknowledged
      - Packets will be resent if not acknowledged
- Packets part of a larger chunk or stream might get out-of-order
      - The receiving kernel will notice
      - Reordering and retransmission will happen as needed

Networking is a dance between the series of hardware devices which are
imperfectly transmitting packets across the "fabric" of interconnected devices
and the network protocols managed in the kernels on the various computer systems
hosting the communicating processes.

Here's a good [[https://en.wikipedia.org/wiki/OSI_model][Networking Reference Model]].

For the popular TCP protocol, these mechanisms give the illusion of a reliable
byte stream as if it were being carried by a dedicated pair of wires.

In the Posix model, once a TCP connection is established, it is handled like any
other I/O stream, with File Descriptors.

**** Miscellaneous Hardware

All of these things interface with Device Drivers in the Kernel.

If application programmers are aware of them at all, they are aware of a
convenient high-level abstraction of them provided by the Kernel!

- Keyboards :: simple byte stream encoding of keys
- Mice :: simple byte stream encoding of buttons and movement
- Frame Buffers feeding to Graphics Displays
      - 2-D arrays of DRAM
      - often dual ported for GPU and CPU access
- Sound input :: [[https://en.wikipedia.org/wiki/Analog-to-digital_converter][Analog-to-Digital converters]]
- Sound output :: [[https://en.wikipedia.org/wiki/Digital-to-analog_converter][Digital-to-Analog converters]]
- Video Camera Input :: Byte stream protocol
- [[https://en.wikipedia.org/wiki/Bluetooth][Bluetooth]] :: Super-complex layers of committee-designed protocols!

- Miscellanea
      - Temperature sensors
      - Open box sensors
      - Fans
